{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.models import FeatureSelectNet\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFusion:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        '''\n",
    "        semg: (tms, 5)\n",
    "        acc:  (tms, 3)\n",
    "        '''\n",
    "        self.data = data\n",
    "    \n",
    "    def fusion(self, mode='kalman'):\n",
    "        if mode == 'kalman':\n",
    "            pass\n",
    "        elif mode == '':\n",
    "            pass\n",
    "        return kalman_fusion()\n",
    "    \n",
    "    def kalman_fusion(self):\n",
    "        data = self.data\n",
    "        tms, ch = data.shape\n",
    "        kf = KalmanFilter(dim_x=ch, dim_z=ch)\n",
    "        kf.x = np.zeros(ch)   # 初始化状态估计值\n",
    "        kf.P *= 1e-2                       # 初始化协方差矩阵\n",
    "        # 定义系统动力学矩阵\n",
    "        kf.F = np.eye(ch)   # 单位矩阵，表示状态不发生变化\n",
    "        # 定义测量矩阵\n",
    "        kf.H = np.eye(ch)   # 单位矩阵，表示测量结果中包含8个模态的信号\n",
    "        # 定义过程噪声和测量噪声的协方差矩阵\n",
    "        kf.Q *= 1e-5\n",
    "        kf.R *= 0.01\n",
    "        \n",
    "        # 合并8个模态的信号成状态向量\n",
    "        measurements_combined = np.vstack(signals).T\n",
    "        # 对每个采样点进行卡尔曼滤波\n",
    "        filtered_states = []\n",
    "        for measurement in measurements_combined:\n",
    "            kf.predict()\n",
    "            kf.update(measurement)\n",
    "            filtered_states.append(np.copy(kf.x))\n",
    "        filtered_states = np.array(filtered_states)\n",
    "        return filtered_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3133579176.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class KalmanFeatureFusion:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        semg, acc = data[0], data[1]\n",
    "        weights = np.array([0.7, 0.3])\n",
    "        self.data = self.falman_fusion(semg, acc, weights)\n",
    "    \n",
    "    def falman_fusion(self, semg, acc, weights):\n",
    "        data_fusion = np.zeros_like((semg.shape))\n",
    "        \n",
    "        x = np.array([0, 0]).reshape(2, 1)  # Initial state vector\n",
    "        P = np.eye(2) * 0.01  # Initial error covariance matrix\n",
    "        \n",
    "        for i, s, a in tqdm(enumerate(zip(semg, acc)), desc=\"Kalman Feature Fusion\", total=len(acc), leave=True):\n",
    "            semg_state, semg_cov = kalman_filter(x, P, s)\n",
    "            acc_state,  acc_cov  = kalman_filter(x, P, a)\n",
    "            semg_score = semg_state[0, 0]\n",
    "            acc_score  = acc_state[0, 0]\n",
    "            data_fusion[i] = [semg_score, acc_score]\n",
    "        return data_fusion\n",
    "        \n",
    "    def kalman_filter(self, x, P, z):\n",
    "        # Define the Kalman filter parameters\n",
    "        dt = 0.1  # Time step\n",
    "        F = np.array([[1, dt], [0, 1]])  # State transition matrix\n",
    "        H = np.array([1, 0]).reshape(1, 2)  # Measurement matrix\n",
    "        Q = np.eye(2) * 1e-5  # Process noise covariance\n",
    "        R = np.eye(1) * 0.1  # Measurement noise covariance\n",
    "        \n",
    "        x_pred = F @ x\n",
    "        P_pred = F @ P @ F.T + Q\n",
    "        K = P_pred @ H.T @ np.linalg.inv(H @ P_pred @ H.T + R)\n",
    "        x = x_pred + K @ (z - H @ x_pred)\n",
    "        P = (np.eye(2) - K @ H) @ P_pred\n",
    "        return x, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class C\n"
     ]
    }
   ],
   "source": [
    "# Define the Kalman filter parameters\n",
    "dt = 0.1  # Time step\n",
    "F = np.array([[1, dt], [0, 1]])  # State transition matrix\n",
    "H = np.array([1, 0]).reshape(1, 2)  # Measurement matrix\n",
    "Q = np.eye(2) * 1e-5  # Process noise covariance\n",
    "R = np.eye(1) * 0.1  # Measurement noise covariance\n",
    "x = np.array([0, 0]).reshape(2, 1)  # Initial state vector\n",
    "P = np.eye(2) * 0.01  # Initial error covariance matrix\n",
    "\n",
    "# Define the classification weights for each modality\n",
    "weights = {'visual': 0.5, 'audio': 0.3, 'haptic': 0.2}\n",
    "\n",
    "# Define the classification thresholds for each modality\n",
    "thresholds = {'visual': 0.7, 'audio': 0.5, 'haptic': 0.3}\n",
    "\n",
    "# Perform Kalman filtering on each modality input\n",
    "def kalman_filter(x, P, z):\n",
    "    x_pred = F @ x\n",
    "    P_pred = F @ P @ F.T + Q\n",
    "    K = P_pred @ H.T @ np.linalg.inv(H @ P_pred @ H.T + R)\n",
    "    x = x_pred + K @ (z - H @ x_pred)\n",
    "    P = (np.eye(2) - K @ H) @ P_pred\n",
    "    return x, P\n",
    "\n",
    "# Combine the results from each modality using Kalman filtering\n",
    "def kalman_fusion(vis_input, aud_input, hap_input):\n",
    "    # Perform Kalman filtering on each modality input\n",
    "    vis_state, vis_cov = kalman_filter(x, P, vis_input)\n",
    "    aud_state, aud_cov = kalman_filter(x, P, aud_input)\n",
    "    hap_state, hap_cov = kalman_filter(x, P, hap_input)\n",
    "\n",
    "    # Compute the classification scores for each modality\n",
    "    vis_score = vis_state[0, 0]\n",
    "    aud_score = aud_state[0, 0]\n",
    "    hap_score = hap_state[0, 0]\n",
    "\n",
    "    # Combine the scores using weighted averaging\n",
    "    score = weights['visual'] * vis_score + \\\n",
    "            weights['audio'] * aud_score + \\\n",
    "            weights['haptic'] * hap_score\n",
    "\n",
    "    # Classify the sample based on the combined score\n",
    "    if score > thresholds['visual']:\n",
    "        return 'Class A'\n",
    "    elif score > thresholds['audio']:\n",
    "        return 'Class B'\n",
    "    else:\n",
    "        return 'Class C'\n",
    "\n",
    "# Example usage of the kalman_fusion() function\n",
    "vis_input = np.array([0.8]).reshape(1, 1)\n",
    "aud_input = np.array([0.6]).reshape(1, 1)\n",
    "hap_input = np.array([0.4]).reshape(1, 1)\n",
    "result = kalman_fusion(vis_input, aud_input, hap_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered States Shape: (1000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 模拟8个模态的信号\n",
    "num_modalities = 8\n",
    "num_samples = 1000\n",
    "\n",
    "signals = [np.random.randn(num_samples) for _ in range(num_modalities)]\n",
    "\n",
    "# 初始化卡尔曼滤波器\n",
    "kf = KalmanFilter(dim_x=num_modalities, dim_z=num_modalities)\n",
    "\n",
    "# 初始化状态估计值和协方差矩阵\n",
    "kf.x = np.zeros(num_modalities)   # 初始化状态估计值\n",
    "kf.P *= 1e-2                       # 初始化协方差矩阵\n",
    "\n",
    "# 定义系统动力学矩阵\n",
    "kf.F = np.eye(num_modalities)   # 单位矩阵，表示状态不发生变化\n",
    "\n",
    "# 定义测量矩阵\n",
    "kf.H = np.eye(num_modalities)   # 单位矩阵，表示测量结果中包含8个模态的信号\n",
    "\n",
    "# 定义过程噪声和测量噪声的协方差矩阵\n",
    "kf.Q *= 1e-5\n",
    "kf.R *= 0.01\n",
    "\n",
    "# 合并8个模态的信号成状态向量\n",
    "measurements_combined = np.vstack(signals).T\n",
    "\n",
    "# 对每个采样点进行卡尔曼滤波\n",
    "filtered_states = []\n",
    "for measurement in measurements_combined:\n",
    "    kf.predict()\n",
    "    kf.update(measurement)\n",
    "    filtered_states.append(np.copy(kf.x))\n",
    "\n",
    "filtered_states = np.array(filtered_states)\n",
    "\n",
    "print(\"Filtered States Shape:\", filtered_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measurements_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./configs/net.yaml', 'r') as net_cfg:\n",
    "    net = yaml.safe_load(net_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e1': [[-1, 1, 'Conv1dNorm', [32, 3, -1, 1]],\n",
       "  [-1, 1, 'MaxPooling', [2, 1, 2]],\n",
       "  [-1, 1, 'Conv1dNorm', [64, 3, -1, 1]],\n",
       "  [-1, 1, 'Conv1d', [32, 1, -1, 1]],\n",
       "  [-2, 1, 'Conv1dNorm', [64, 3, -1, 1]],\n",
       "  [-1, 1, 'MaxPooling', [2, 1, 2]],\n",
       "  [-1, 1, 'Conv1dNorm', [128, 3, -1, 1]],\n",
       "  [-1, 1, 'Conv1d', [64, 1, -1, 1]],\n",
       "  [-2, 1, 'Conv1dNorm', [128, 3, -1, 1]]],\n",
       " 'e2': [[-1, 1, 'Conv1dNorm', [64, 3, -1, 1]],\n",
       "  [-1, 1, 'Conv1d', [32, 1, -1, 1]],\n",
       "  [-2, 1, 'Conv1dNorm', [64, 3, -1, 1]],\n",
       "  [-1, 1, 'MaxPooling', [2, 1, 2]],\n",
       "  [-1, 1, 'Conv1dNorm', [128, 3, -1, 1]],\n",
       "  [-1, 1, 'Conv1d', [64, 1, -1, 1]],\n",
       "  [-2, 1, 'Conv1dNorm', [128, 3, -1, 1]]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2981, 10, 8), (2981,), (2981, 80))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('./runs/data/user1/feature_images.npy')\n",
    "labels = np.load('./runs/data/user1/feature_image_labels.npy')\n",
    "features = np.reshape(data, (data.shape[0], -1))\n",
    "features = preprocessing.StandardScaler().fit_transform(features)\n",
    "data.shape, labels.shape, features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9423205902079141"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## semg前4个特征\n",
    "f1 = features[:, :32]\n",
    "X_train, X_test, y_train, y_test = train_test_split(f1, labels, test_size=0.5, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8, weights='uniform', algorithm='auto', metric='minkowski')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631490787269682"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=8, weights='uniform', algorithm='auto', metric='minkowski')\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones((32, 200, 10))\n",
    "model = Attention(\n",
    "    dim=10,\n",
    "    num_heads=2,\n",
    ")\n",
    "input = input.to('cuda')\n",
    "model = model.to('cuda')\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数\n",
    "                               batch_size=32,       # 输出的batch大小\n",
    "                               shuffle=True,       # 数据是否打乱\n",
    "                               num_workers=2)      # 进程数, 0表示只有主进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(images):\n",
    "    # （X-X的均值）/ X的标准差\n",
    "    images = (images - np.mean(images, axis=0)[None, :, :]) / np.std(images, axis=0)[None, :, :]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((298383, 8), (298383,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('./runs/data/user1/signal.npy')\n",
    "labels = np.load('./runs/data/user1/labels.npy')\n",
    "# data = standardize(data)\n",
    "data.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(np.isnan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones((32, 12, 8))\n",
    "model = FeatureSelectNet(\n",
    "    input_shape=input.shape,\n",
    "    hidden_size=64,\n",
    "    num_layers=4,\n",
    "    bias=True,\n",
    "    batch_first=True,\n",
    ")\n",
    "input = input.to('cuda')\n",
    "model = model.to('cuda')\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "batch_size = 32\n",
    "data_size = 100\n",
    "feature_size = 12\n",
    "classes = 8\n",
    "x = torch.rand_like(torch.ones((batch_size*n, data_size, feature_size)))\n",
    "y = torch.zeros((batch_size*n, classes))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(MyDataset(x,y), shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureSelectNet(\n",
    "    input_shape=x.shape,\n",
    "    hidden_size=32,\n",
    "    num_layers=4,\n",
    "    bias=True,\n",
    ")\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train epoch 0] loss: 0.000, acc: 0.153: 100%|██████████| 100/100 [00:00<00:00, 255.35it/s]\n",
      "0.0 0.153125\n",
      "[train epoch 1] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 246.30it/s]\n",
      "0.0 0.1425\n",
      "[train epoch 2] loss: 0.000, acc: 0.129: 100%|██████████| 100/100 [00:00<00:00, 246.51it/s]\n",
      "0.0 0.129375\n",
      "[train epoch 3] loss: 0.000, acc: 0.149: 100%|██████████| 100/100 [00:00<00:00, 245.99it/s]\n",
      "0.0 0.14875\n",
      "[train epoch 4] loss: 0.000, acc: 0.140: 100%|██████████| 100/100 [00:00<00:00, 244.90it/s]\n",
      "0.0 0.1403125\n",
      "[train epoch 5] loss: 0.000, acc: 0.140: 100%|██████████| 100/100 [00:00<00:00, 242.29it/s]\n",
      "0.0 0.1396875\n",
      "[train epoch 6] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 246.12it/s]\n",
      "0.0 0.141875\n",
      "[train epoch 7] loss: 0.000, acc: 0.144: 100%|██████████| 100/100 [00:00<00:00, 243.58it/s]\n",
      "0.0 0.14375\n",
      "[train epoch 8] loss: 0.000, acc: 0.148: 100%|██████████| 100/100 [00:00<00:00, 244.76it/s]\n",
      "0.0 0.1484375\n",
      "[train epoch 9] loss: 0.000, acc: 0.146: 100%|██████████| 100/100 [00:00<00:00, 244.24it/s]\n",
      "0.0 0.1459375\n",
      "[train epoch 10] loss: 0.000, acc: 0.143: 100%|██████████| 100/100 [00:00<00:00, 245.79it/s]\n",
      "0.0 0.1434375\n",
      "[train epoch 11] loss: 0.000, acc: 0.143: 100%|██████████| 100/100 [00:00<00:00, 261.72it/s]\n",
      "0.0 0.143125\n",
      "[train epoch 12] loss: 0.000, acc: 0.138: 100%|██████████| 100/100 [00:00<00:00, 283.59it/s]\n",
      "0.0 0.1375\n",
      "[train epoch 13] loss: 0.000, acc: 0.138: 100%|██████████| 100/100 [00:00<00:00, 264.52it/s]\n",
      "0.0 0.138125\n",
      "[train epoch 14] loss: 0.000, acc: 0.146: 100%|██████████| 100/100 [00:00<00:00, 247.80it/s]\n",
      "0.0 0.145625\n",
      "[train epoch 15] loss: 0.000, acc: 0.147: 100%|██████████| 100/100 [00:00<00:00, 304.82it/s]\n",
      "0.0 0.1475\n",
      "[train epoch 16] loss: 0.000, acc: 0.148: 100%|██████████| 100/100 [00:00<00:00, 310.64it/s]\n",
      "0.0 0.1478125\n",
      "[train epoch 17] loss: 0.000, acc: 0.139: 100%|██████████| 100/100 [00:00<00:00, 312.03it/s]\n",
      "0.0 0.1390625\n",
      "[train epoch 18] loss: 0.000, acc: 0.154: 100%|██████████| 100/100 [00:00<00:00, 306.70it/s]\n",
      "0.0 0.15375\n",
      "[train epoch 19] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 333.40it/s]\n",
      "0.0 0.1421875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    acc_loss = torch.zeros(1).to(device)\n",
    "    acc_num = torch.zeros(1).to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    dataloader = tqdm(dataloader, file=sys.stdout)\n",
    "    for step, data in enumerate(dataloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images)\n",
    "        _, idxs_pred = torch.max(pred, dim=1)\n",
    "        _, idxs_true = torch.max(labels, dim=1)\n",
    "        acc_num += torch.eq(idxs_pred, idxs_true).sum()\n",
    "\n",
    "        loss = loss_func(pred, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        acc_loss += loss.detach()\n",
    "        dataloader.desc = '[train epoch {}] loss: {:.3f}, acc: {:.3f}'.format(\n",
    "                                                                            epoch,\n",
    "                                                                            acc_loss.item() / (step + 1),\n",
    "                                                                            acc_num.item() / sample_num\n",
    "                                                                        )\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(acc_loss.item() / (step + 1), acc_num.item() / sample_num)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4af97d6d26fbb5ceba72f745996bb1e3a12e47211a7f7801a7e7329a611e8a11"
  },
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "tt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
