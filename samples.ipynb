{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.models import FeatureSelectNet, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 200, 10])\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones((32, 200, 10))\n",
    "model = Attention(\n",
    "    dim=10,\n",
    "    num_heads=2,\n",
    ")\n",
    "input = input.to('cuda')\n",
    "model = model.to('cuda')\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数\n",
    "                               batch_size=32,       # 输出的batch大小\n",
    "                               shuffle=True,       # 数据是否打乱\n",
    "                               num_workers=2)      # 进程数, 0表示只有主进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(images):\n",
    "    # （X-X的均值）/ X的标准差\n",
    "    images = (images - np.mean(images, axis=0)[None, :, :]) / np.std(images, axis=0)[None, :, :]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((298383, 8), (298383,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('./runs/data/user1/signal.npy')\n",
    "labels = np.load('./runs/data/user1/labels.npy')\n",
    "# data = standardize(data)\n",
    "data.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(np.isnan(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones((32, 12, 8))\n",
    "model = FeatureSelectNet(\n",
    "    input_shape=input.shape,\n",
    "    hidden_size=64,\n",
    "    num_layers=4,\n",
    "    bias=True,\n",
    "    batch_first=True,\n",
    ")\n",
    "input = input.to('cuda')\n",
    "model = model.to('cuda')\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self,):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "batch_size = 32\n",
    "data_size = 100\n",
    "feature_size = 12\n",
    "classes = 8\n",
    "x = torch.rand_like(torch.ones((batch_size*n, data_size, feature_size)))\n",
    "y = torch.zeros((batch_size*n, classes))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(MyDataset(x,y), shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureSelectNet(\n",
    "    input_shape=x.shape,\n",
    "    hidden_size=32,\n",
    "    num_layers=4,\n",
    "    bias=True,\n",
    ")\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train epoch 0] loss: 0.000, acc: 0.153: 100%|██████████| 100/100 [00:00<00:00, 255.35it/s]\n",
      "0.0 0.153125\n",
      "[train epoch 1] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 246.30it/s]\n",
      "0.0 0.1425\n",
      "[train epoch 2] loss: 0.000, acc: 0.129: 100%|██████████| 100/100 [00:00<00:00, 246.51it/s]\n",
      "0.0 0.129375\n",
      "[train epoch 3] loss: 0.000, acc: 0.149: 100%|██████████| 100/100 [00:00<00:00, 245.99it/s]\n",
      "0.0 0.14875\n",
      "[train epoch 4] loss: 0.000, acc: 0.140: 100%|██████████| 100/100 [00:00<00:00, 244.90it/s]\n",
      "0.0 0.1403125\n",
      "[train epoch 5] loss: 0.000, acc: 0.140: 100%|██████████| 100/100 [00:00<00:00, 242.29it/s]\n",
      "0.0 0.1396875\n",
      "[train epoch 6] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 246.12it/s]\n",
      "0.0 0.141875\n",
      "[train epoch 7] loss: 0.000, acc: 0.144: 100%|██████████| 100/100 [00:00<00:00, 243.58it/s]\n",
      "0.0 0.14375\n",
      "[train epoch 8] loss: 0.000, acc: 0.148: 100%|██████████| 100/100 [00:00<00:00, 244.76it/s]\n",
      "0.0 0.1484375\n",
      "[train epoch 9] loss: 0.000, acc: 0.146: 100%|██████████| 100/100 [00:00<00:00, 244.24it/s]\n",
      "0.0 0.1459375\n",
      "[train epoch 10] loss: 0.000, acc: 0.143: 100%|██████████| 100/100 [00:00<00:00, 245.79it/s]\n",
      "0.0 0.1434375\n",
      "[train epoch 11] loss: 0.000, acc: 0.143: 100%|██████████| 100/100 [00:00<00:00, 261.72it/s]\n",
      "0.0 0.143125\n",
      "[train epoch 12] loss: 0.000, acc: 0.138: 100%|██████████| 100/100 [00:00<00:00, 283.59it/s]\n",
      "0.0 0.1375\n",
      "[train epoch 13] loss: 0.000, acc: 0.138: 100%|██████████| 100/100 [00:00<00:00, 264.52it/s]\n",
      "0.0 0.138125\n",
      "[train epoch 14] loss: 0.000, acc: 0.146: 100%|██████████| 100/100 [00:00<00:00, 247.80it/s]\n",
      "0.0 0.145625\n",
      "[train epoch 15] loss: 0.000, acc: 0.147: 100%|██████████| 100/100 [00:00<00:00, 304.82it/s]\n",
      "0.0 0.1475\n",
      "[train epoch 16] loss: 0.000, acc: 0.148: 100%|██████████| 100/100 [00:00<00:00, 310.64it/s]\n",
      "0.0 0.1478125\n",
      "[train epoch 17] loss: 0.000, acc: 0.139: 100%|██████████| 100/100 [00:00<00:00, 312.03it/s]\n",
      "0.0 0.1390625\n",
      "[train epoch 18] loss: 0.000, acc: 0.154: 100%|██████████| 100/100 [00:00<00:00, 306.70it/s]\n",
      "0.0 0.15375\n",
      "[train epoch 19] loss: 0.000, acc: 0.142: 100%|██████████| 100/100 [00:00<00:00, 333.40it/s]\n",
      "0.0 0.1421875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    acc_loss = torch.zeros(1).to(device)\n",
    "    acc_num = torch.zeros(1).to(device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    sample_num = 0\n",
    "    dataloader = tqdm(dataloader, file=sys.stdout)\n",
    "    for step, data in enumerate(dataloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        sample_num += images.shape[0]\n",
    "\n",
    "        pred = model(images)\n",
    "        _, idxs_pred = torch.max(pred, dim=1)\n",
    "        _, idxs_true = torch.max(labels, dim=1)\n",
    "        acc_num += torch.eq(idxs_pred, idxs_true).sum()\n",
    "\n",
    "        loss = loss_func(pred, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        acc_loss += loss.detach()\n",
    "        dataloader.desc = '[train epoch {}] loss: {:.3f}, acc: {:.3f}'.format(\n",
    "                                                                            epoch,\n",
    "                                                                            acc_loss.item() / (step + 1),\n",
    "                                                                            acc_num.item() / sample_num\n",
    "                                                                        )\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print(acc_loss.item() / (step + 1), acc_num.item() / sample_num)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4af97d6d26fbb5ceba72f745996bb1e3a12e47211a7f7801a7e7329a611e8a11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('mocut')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
